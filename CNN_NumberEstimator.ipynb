{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_NumberEstimator.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBLda8C9KfqZ",
        "colab_type": "code",
        "outputId": "93e8ae45-d46a-4b28-e1b0-009deccee687",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1217
        }
      },
      "source": [
        "###################################\n",
        "## CREATE IMAGES WITH RANDOMLY \n",
        "##  POSITIONED SQUARES WITH VARIED SIZE\n",
        "#################################\n",
        "# Good source about pixel manipulation: http://pythoninformer.com/python-libraries/numpy/numpy-and-images/\n",
        "\n",
        "import numpy as np\n",
        "import scipy.misc as smp\n",
        "import random\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "from IPython.display import HTML\n",
        "style = \"<style>svg{width:500% !important;height:500% !important;}</style>\"\n",
        "\n",
        "\n",
        "max_objects = 8\n",
        "img_size = 28\n",
        "\n",
        "\n",
        "\n",
        "###################################\n",
        "## Function that creates N (= argument of the function) Squares\n",
        "##  randomly positioned with varying size\n",
        "##  AND corresponding one-hot-encoded number of objects .\n",
        "########\n",
        "def Create_N_Sqaures(n_objects):\n",
        "\n",
        "    \n",
        "    n_neighbours_mean = 2\n",
        "    data = np.zeros((img_size, img_size), dtype=np.uint8)\n",
        "    obj_size_var = 2\n",
        "\n",
        "\n",
        "    for n in range(n_objects):\n",
        "        breaky = 0\n",
        "        max_put_try = 1000    #Number of attempts to place square correctly: without overlap, within the borders of the image.\n",
        "        put_try=0\n",
        "        current_obj_size_var =  random.randint(0,obj_size_var)\n",
        "        n_neighbours = n_neighbours_mean - current_obj_size_var\n",
        "\n",
        "        # Now try to put square correctly into image for max_put_try.\n",
        "        # Strategy: choose random x and y coordinate as center of the square: draw n_neighbours around center in each direction\n",
        "        while (breaky == 0):\n",
        "            rand_pixel_1 = random.randint(0,img_size-1)\n",
        "            rand_pixel_2 = random.randint(0, img_size-1)\n",
        "            dist_to_squ = 2\n",
        "            # Check if object within borders\n",
        "            if (rand_pixel_1 + n_neighbours <= img_size - dist_to_squ and rand_pixel_2 + n_neighbours <= img_size - dist_to_squ and rand_pixel_1 - n_neighbours > 0 + dist_to_squ and rand_pixel_2 - n_neighbours > 0 + dist_to_squ):\n",
        "                breaky=1\n",
        "                # Check if any objects are overlapping\n",
        "                for i in range(2 * n_neighbours + 2*(dist_to_squ) ):\n",
        "                    for j in range(2 * n_neighbours + 2*(dist_to_squ) ):\n",
        "                      #if (rand_pixel_1 - n_neighbours -1  + i <= img_size - 3 and rand_pixel_2 - n_neighbours - 1 + j and rand_pixel_1 - n_neighbours -1  + i > 0 + 3 and rand_pixel_2 - n_neighbours - 1 + j > 0 + 3):\n",
        "                      if(data[rand_pixel_1 - n_neighbours - dist_to_squ  + i, rand_pixel_2 - n_neighbours -dist_to_squ  + j] == 255):\n",
        "                          breaky=0\n",
        "            put_try += 1\n",
        "            if(put_try >= max_put_try):\n",
        "                breaky = 1\n",
        "                print(\"ATTENTION: OBJECTS COULD NOT FIT INTO WINDOW. CHOOSE DIFFERENT SIZE FOR WINDOW OR OBJECTS\")\n",
        "                exit()\n",
        "        data[rand_pixel_1,rand_pixel_2] = 255\n",
        "\n",
        "        for i in range(2*n_neighbours):\n",
        "            for j in range(2 * n_neighbours ):\n",
        "                data[rand_pixel_1 - n_neighbours + i, rand_pixel_2 - n_neighbours + j] = 255\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "    # Data 2D-image --> 1D-array ( for NN as Input )\n",
        "    data_flatten = data.flatten()\n",
        "    # Build one-hot array from number of objects\n",
        "    n_obj_one_hot = np.zeros(max_objects)\n",
        "    n_objects_m_1 = n_objects-1\n",
        "    n_obj_one_hot[n_objects_m_1] = 1\n",
        "\n",
        "    return data_flatten, n_obj_one_hot\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###################################\n",
        "## Function that creates N images with set of squares\n",
        "##   AND corresponding one-hot-encoded number of objects.\n",
        "######\n",
        "def Create_N_Images(n_images, only_one_number=False, n_squares=5):\n",
        "\n",
        "    n_objects = random.randint(1, max_objects)\n",
        "    if (only_one_number):\n",
        "        n_objects = n_squares\n",
        "\n",
        "    mult_img, mult_class = Create_N_Sqaures(n_objects)\n",
        "    for i in range(n_images):\n",
        "        n_objects = random.randint(1, max_objects)\n",
        "        if (only_one_number):\n",
        "            n_objects = n_squares\n",
        "\n",
        "        data_flatten, n_obj_one_hot = Create_N_Sqaures(n_objects)\n",
        "        mult_img = np.vstack([mult_img, data_flatten])\n",
        "        mult_class = np.vstack((mult_class, n_obj_one_hot))\n",
        "\n",
        "    return mult_img, mult_class\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Prepare Training data\n",
        "mult_img, mult_class = Create_N_Images(20000)  # original 20000!!!!!\n",
        "#np.save('Object_Sets_Array/trX', mult_img)\n",
        "#np.save('Object_Sets_Array/trY', mult_class)\n",
        "print(mult_img.shape)\n",
        "print(mult_class.shape)\n",
        "\n",
        "# Prepare Test data\n",
        "mult_img_T, mult_class_T = Create_N_Images(2000)\n",
        "#np.save('Object_Sets_Array/trX', mult_img_T)\n",
        "#np.save('Object_Sets_Array/trY', mult_class_T)\n",
        "print(mult_img_T.shape)\n",
        "print(mult_class_T.shape)\n",
        "\n",
        "#recovered_file = np.load('Object_Sets_Array/trX.npy')\n",
        "print(mult_img_T.shape)\n",
        "print(mult_class_T.shape)\n",
        "\n",
        "\n",
        "########\n",
        "## SHOW EXAMPLE PICS\n",
        "###############\n",
        "print(mult_class[0,:])\n",
        "#get_ipython().__class__.__name__ = \"ZMQInteractiveShell\"\n",
        "#print(get_ipython().__class__.__name__ == \"ZMQInteractiveShell\")\n",
        "img = Image.fromarray(np.reshape(mult_img[0,:], (img_size,img_size)))  # Create a PIL image\n",
        "img = img.resize((200,200))\n",
        "display(img)\n",
        "img.show()  # View in default viewer\n",
        "\n",
        "print(mult_class[1,:])\n",
        "img = Image.fromarray(np.reshape(mult_img[1,:], (img_size,img_size)))  # Create a PIL image\n",
        "img = img.resize((200,200))\n",
        "display(img)\n",
        "img.show()  # View in default viewer\n",
        "\n",
        "print(mult_class[2,:])\n",
        "img = Image.fromarray(np.reshape(mult_img[2,:], (img_size,img_size)))  # Create a PIL image\n",
        "img.show()  # View in default viewer\n",
        "img = img.resize((200,200))\n",
        "display(img)\n",
        "\n",
        "print(mult_class[3,:])\n",
        "img = Image.fromarray(np.reshape(mult_img[3,:], (img_size,img_size)))  # Create a PIL image\n",
        "img.show()  # View in default viewer\n",
        "img = img.resize((200,200))\n",
        "display(img)\n",
        "\n",
        "print(mult_class[4,:])\n",
        "img = Image.fromarray(np.reshape(mult_img[4,:], (img_size,img_size)))  # Create a PIL image\n",
        "img.show()  # View in default viewer\n",
        "img = img.resize((200,200))\n",
        "display(img)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20001, 784)\n",
            "(20001, 8)\n",
            "(2001, 784)\n",
            "(2001, 8)\n",
            "(2001, 784)\n",
            "(2001, 8)\n",
            "[0. 1. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAAAAACIM/FCAAAAhElEQVR4nO3YMQqAMBBFwSje/8ra\nWAeUxXzWmVbQfQSCyRgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFBgW/blc/bw+Vj760HCCEkjJI2Q\nNELSCEkjJE2bkKP4fffP+fengzYrIiSNkDRtQqq332W3Mm1WREgaIWnahAAAAAAAAAAAAMA/XV2e\nAj+L6ZCuAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=200x200 at 0x7F37BF7B3198>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 1. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAAAAACIM/FCAAAApUlEQVR4nO3cwQpAQBRAUfz/P7NW\nEmVy6Zylmp675TXTBAAAAAAAUfPh0/X+kbctb7/AU4TUCKkRUiOkRkiNkBohNUJqhNQIqRFSI6RG\nCAAAAAAAcNGgbeSzDegxI3/zW0FIjZAaITVCaoTUCKkRUiOkRkiNkBohNUJqhAAAAADwRWPv89wv\n0g2d9ZvvWkJqhNQIqRFSI6RGCAAAAAAAAAAAAFCwARekA4puvwpiAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=200x200 at 0x7F37BF7B3160>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAAAAACIM/FCAAAApklEQVR4nO3bMQ6DMBAAQYjy/y+T\nKi2CAPHKmmmRkVcufV4WAAAAAAAAAAAGW88v2a7+4BGv0Ru4i5AaITVCaoTUCKkRAgAAAAAAAAAA\nABRUnn98/fw4ZZqZRiE1QmqE1AipEVIjBAAAAAAAOOiuEY5t7+M/5kSmuVYQUiOkRkiNkBohNUJq\n3qM3sOvEOPM0JyKkRkiNkBohNUJqhNRMEwIAAADwqA/jUQRyuuAiCgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=200x200 at 0x7F37BF7B3128>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 1. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAAAAACIM/FCAAABCklEQVR4nO3cwWoCMRRAUSv+/y+3\nG1cySNMOk8vznKUgegnE+HTmdgMAAAAAgKivw0e/15+y2333GziLkBohNUJqhNQIqRFSI6RGSI2Q\nmjEhjyte5IpZxpgVEVIjpGZMyPH22xzvvjVmRYTUCKkZE3LJ6ffPnsfm33wajFkRITVCasaEtLff\nhVP4mBURUiOkRggAAADAR9nwZ42FHwYXjBkHCakRUjMmBAAAPsdZI4Dtdxsa831ESI2QGiE1QmqE\n1AipEVIjpEZIjZCa6HWI60OZMSsipEZIzZiQs7bf9Tn1yw7730H3mBURUiOkRkiNkBohNUJq9g0f\nXD9yTEiNkJoxIQAAAAAAkPUDXhoH5nLKFQQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=200x200 at 0x7F37BF7B3128>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 1. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAAAAACIM/FCAAAA90lEQVR4nO3bQQrCMBQAURXvf2Xd\nuCzSIMbh+95WwQyB9kvTywUAAAAAAKKuv17Asce7Dw/XfPvOQvYTUiOkRkiNkBohNUJq7me+9G4W\nrYzPY3ZESI2QGiE1QmqE1AipOTX97rc+U4/ZESE1QmqE1AipEVIjBAAA4EOVExjHFs4xj/ljJaRG\nSM2YkJ3PENdfClkwZkeE1AipEVIjpEZIjZCalek3/RrJmB0RUiOkZkxI9ADzy8JFfcyOCKkRUjMm\nZOfl96sT8pgdEVIjpEZIjZAaITVCasaEAPATW579PTb81pgbopAaITVjQgAAAAAAAAAAAOA/PQG/\nUgbTU76JawAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=200x200 at 0x7F37BF7B3128>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zwkd8MPpsDhy",
        "colab_type": "code",
        "outputId": "4a183251-f975-4272-ef01-5fbfbcbc7d1a",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "source": [
        "#########################\n",
        "## You can also upload files from your local drive \n",
        "## (for the case you it takes a lot of time to create the data and you do not want to create them in each runtime session again)\n",
        "###############################################\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "!pwd\n",
        "\n",
        "import numpy as np\n",
        "##### the file names in np.load (...) should be the same as it says in the output after you uploaded them: e.g. \"Saving teX.npy to .....\" --- ... is how you can access the data now\n",
        "trX = np.load('trX (3).npy')\n",
        "trY = np.load('trY (3).npy')\n",
        "teX = np.load('teX (3).npy')\n",
        "teY = np.load('teY (3).npy')\n",
        "\n",
        "print(trY[0])\n",
        "print(teY[0])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d15ed186-5836-4c4b-ad68-610ae5f0305a\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-d15ed186-5836-4c4b-ad68-610ae5f0305a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-245488a4c30b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m##### the file names in np.load (...) should be the same as it says in the output after you uploaded them: e.g. \"Saving teX.npy to .....\" --- ... is how you can access the data now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trX (3).npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtrY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trY (3).npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mteX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'teX (3).npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'trX (3).npy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDU656rbApPW",
        "colab_type": "code",
        "outputId": "4d0a6c49-cef1-4b66-9242-a547aacb5f4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "##############################\n",
        "## Create a directory 'logs' to save the results\n",
        "###################################\n",
        "\n",
        "import os\n",
        "# Where to run code?: /content/logs\n",
        "!pwd\n",
        "!ls\n",
        "!mkdir logs\n",
        "os.chdir('/content/logs')\n",
        "!ls\n",
        "\n",
        "os.system('fuser 6006/tcp -k')\n",
        "os.chdir('/content/')\n",
        "\n",
        "############################### \n",
        "## or remove all logs you have done so far\n",
        "################################\n",
        "#!rm -rf *\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hd3NIwdL-E37",
        "colab_type": "code",
        "outputId": "027bc1df-bc91-439b-cc15-03ae41e5099a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "######################\n",
        "## This is required to run tensorboard on Google Colab - Jupyter Notebook: \n",
        "##  This will create a link ending with ... .ngrok.io which you can open to get to tensorboard\n",
        "#####################################\n",
        "\n",
        "\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "LOG_DIR = '/content/logs'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "#--debugger_port 6064\n",
        "\n",
        "get_ipython().system_raw('/content/ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-20 19:18:48--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.4.75.11, 52.203.102.189, 52.204.136.9, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.4.75.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16648024 (16M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  15.88M  8.60MB/s    in 1.8s    \n",
            "\n",
            "2019-05-20 19:18:51 (8.60 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [16648024/16648024]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ngrok                   \n",
            "https://2307e3e2.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSBiGWZDw8Jx",
        "colab_type": "code",
        "outputId": "92cf5ccf-2aaa-4683-baf7-8c29bbaa6602",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5823
        }
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "tf.reset_default_graph()\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.misc as smp\n",
        "import os\n",
        "from tensorflow.python import debug as tf_debug\n",
        "#from fs.osfs import OSFS\n",
        "import datetime\n",
        "now = datetime.datetime.now()\n",
        "from tensorflow.contrib.tensorboard.plugins import projector\n",
        "\n",
        "\n",
        "\n",
        "################################\n",
        "## AUXILIARY FUNCTIONS\n",
        "################################\n",
        "def array_to_image(data):\n",
        "    img = smp.toimage(np.reshape(data, (img_size,img_size)))\n",
        "    return  img\n",
        "\n",
        "def init_weights(shape, name):\n",
        "    return tf.Variable(tf.random_normal(shape, stddev=0.01), name=name)\n",
        "  \n",
        "def conv_to_tensorboard(conv_layer, conv_name, scope_name ):\n",
        "    with tf.variable_scope(scope_name):\n",
        "        kernel_str = conv_name + '/kernel'\n",
        "        kernel = tf.get_collection(tf.GraphKeys.VARIABLES, kernel_str)[0]\n",
        "         # scale weights to [0 1], type is still float\n",
        "        x_min = tf.reduce_min(kernel)\n",
        "        x_max = tf.reduce_max(kernel)\n",
        "        kernel_0_to_1 = (kernel - x_min) / (x_max - x_min)\n",
        "        # to tf.image_summary format [batch_size, height, width, channels]\n",
        "        kernel_transposed = tf.transpose (kernel_0_to_1, [3, 0, 1, 2])\n",
        "        # this will display random 3 filters from the 64 in conv1\n",
        "        tf.summary.image('conv1_filters', kernel_transposed,max_outputs=32)\n",
        "        \n",
        "def layer_and_input_activ_to_tensorboard(layer, inputt, input_id, scope_name, img_w, img_h):\n",
        "    with tf.name_scope(\"Sizes\"):\n",
        "      layer_shape = layer.get_shape().as_list()\n",
        "      widthy = layer.get_shape().as_list()[1]\n",
        "      whole_layer = layer\n",
        "    imgy = tf.reshape(layer, [-1, img_w, img_h, 1])    \n",
        "    imgy2 = tf.reshape(inputt, [-1, img_size, img_size, 1])\n",
        "    input_str = 'Input_' + input_id\n",
        "    layer_str = scope_name + '_of_' + input_str\n",
        "    tf.summary.image(input_id, imgy)\n",
        "    tf.summary.image(input_id, imgy2)\n",
        "\n",
        "    \n",
        "################################\n",
        "## NN - Models\n",
        "################################\n",
        "# This network is the same as the previous one except with an extra hidden layer + dropout\n",
        "\n",
        "def fully_connected_net(X, w_h, w_h2, w_o, p_keep_input, p_keep_hidden,is_trainy):\n",
        "    # Add layer name scopes for better graph visualization\n",
        "    with tf.name_scope(\"layer1\"):\n",
        "        X = tf.nn.dropout(X, p_keep_input)\n",
        "        h = tf.nn.relu(tf.matmul(X, w_h))\n",
        "    with tf.name_scope(\"layer2\"):\n",
        "        h = tf.nn.dropout(h, p_keep_hidden)\n",
        "        h2 = tf.nn.relu(tf.matmul(h, w_h2))\n",
        "    with tf.name_scope(\"layer3\"):\n",
        "        h2 = tf.nn.dropout(h2, p_keep_hidden)\n",
        "        h3 = tf.nn.relu(tf.matmul(h2, w_h3))\n",
        "    with tf.name_scope(\"layer4\"):\n",
        "        h3 = tf.nn.dropout(h3, p_keep_hidden)\n",
        "        h4 = tf.nn.relu(tf.matmul(h3, w_h4))\n",
        "    with tf.name_scope(\"layer5\"):\n",
        "        h4 = tf.nn.dropout(h4, p_keep_hidden)\n",
        "        h5 = tf.nn.relu(tf.matmul(h4, w_h5))\n",
        "    with tf.name_scope(\"layer5\"):\n",
        "        h5 = tf.nn.dropout(h5, p_keep_hidden)\n",
        "        return tf.matmul(h5, w_o)\n",
        "\n",
        "\n",
        "\n",
        "def conv_net(x_arr, n_classes, dropout, is_training, reuse):\n",
        "    # data input might come as a 1-D vector of 784 features (28*28 pixels)\n",
        "    # Reshape to match picture format [Height x Width x Channel]\n",
        "    # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n",
        "    x = tf.reshape(x_arr, shape=[-1, img_size, img_size, 1])\n",
        "\n",
        "    # Convolution Layer with 32 filters and a kernel size of 5\n",
        "    with tf.name_scope(\"conv1\"):\n",
        "      #kernel = _variable_with_weight_decay('weights', shape=[5, 5, 3, 64],\n",
        "       #                                stddev=1e-4, wd=0.0)\n",
        "      #conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')\n",
        "      #conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)\n",
        "      conv1 = tf.layers.conv2d(inputs=x,filters=8,kernel_size=[5, 5],padding=\"same\",activation=tf.nn.relu, name='conv1')\n",
        "      # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n",
        "      conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n",
        "\n",
        "    # Convolution Layer with 64 filters and a kernel size of 3\n",
        "    with tf.name_scope(\"conv2\"):\n",
        "      conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n",
        "      # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n",
        "      conv2 = tf.layers.max_pooling2d(conv2, 2, 2)\n",
        "\n",
        "    # Flatten the data to a 1-D vector for the fully connected layer\n",
        "    conv2_flatten = tf.contrib.layers.flatten(conv2)\n",
        "    # Fully connected layer (in tf contrib folder for now)\n",
        "    fc1 = tf.layers.dense(conv2_flatten, 9)   #original 1024\n",
        "    # Apply Dropout (if is_training is False, dropout is not applied)\n",
        "    fc1 = tf.layers.dropout(fc1, rate=dropout, training=is_training)\n",
        "    \n",
        "    # Output layer, class prediction\n",
        "    out = tf.layers.dense(fc1, n_classes)\n",
        "    \n",
        "    ######################\n",
        "    #### PLOT LAYERS IN TENSORBOARD\n",
        "    ######################\n",
        "    conv_to_tensorboard(conv1, 'conv1', 'Conv1_Kernel_visualization' ) \n",
        "    \n",
        "    layer_shape = fc1[0].get_shape()\n",
        "    widthy = fc1.get_shape().as_list()[1]\n",
        "    whole_layer = fc1\n",
        "    \n",
        "    with tf.variable_scope('Last_layer_activation'):\n",
        "      for obj in range(5):   \n",
        "        layer_and_input_activ_to_tensorboard(fc1[obj:obj+1], x[obj:obj+1], str(obj), 'Last_layer_activation',3,3)\n",
        "       \n",
        "    with tf.variable_scope('conv1'):\n",
        "      for obj in range(5):   \n",
        "        layer_and_input_activ_to_tensorboard(conv1[obj:obj+1], x[obj:obj+1], str(obj), 'conv1_activation',img_size,img_size)  \n",
        "    \n",
        "      \n",
        "\n",
        "       \n",
        "    return out, fc1\n",
        "\n",
        "  \n",
        "\n",
        "################################\n",
        "## LOAD DATA\n",
        "################################\n",
        "\n",
        "#mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "#trX, trY, teX, teY = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels\n",
        "\n",
        "## If you have uploaded files above:\n",
        "#trX = np.load('trX.npy')\n",
        "#trY = np.load('trY.npy')\n",
        "#teX = np.load('teX.npy')\n",
        "#teY = np.load('teY.npy')\n",
        "\n",
        "# If you have created the files within this notebook:\n",
        "trX = mult_img\n",
        "trY = mult_class\n",
        "teX = mult_img_T\n",
        "teY = mult_class_T\n",
        "\n",
        "print(trX.shape)\n",
        "print(trY.shape)\n",
        "print(teX.shape)\n",
        "print(teY.shape)\n",
        "\n",
        "\n",
        "\n",
        "##########################################\n",
        "## CREATE QUANTITIES/PLACEHOLDERS and SET THEM INTO NN\n",
        "#########################################\n",
        "\n",
        "#Step 2 - Create input and output placeholders for data\n",
        "X = tf.placeholder(\"float\", [None, trX[0,:].size], name=\"X\")\n",
        "Y = tf.placeholder(\"float\", [None, trY[0,:].size], name=\"Y\")\n",
        "is_training = tf.placeholder(tf.bool)\n",
        "failed_object = tf.placeholder(tf.int32, name=\"FAILY\")\n",
        "failed_object_string = tf.placeholder(dtype=tf.string)\n",
        "\n",
        "#Step 3 - Initialize weights\n",
        "'''\n",
        "n_h_neurons = 100    #original 625\n",
        "w_h = init_weights([trX[0,:].size, n_h_neurons], \"w_h\")\n",
        "w_h2 = init_weights([n_h_neurons, n_h_neurons], \"w_h2\")\n",
        "w_h3 = init_weights([n_h_neurons, n_h_neurons], \"w_h2\")\n",
        "w_h4 = init_weights([n_h_neurons, n_h_neurons], \"w_h2\")\n",
        "w_h5 = init_weights([n_h_neurons, n_h_neurons], \"w_h2\")\n",
        "w_o = init_weights([n_h_neurons, trY[0,:].size], \"w_o\")\n",
        "\n",
        "#Step 4 - Add histogram summaries for weights\n",
        "tf.summary.histogram(\"w_h_summ\", w_h)\n",
        "tf.summary.histogram(\"w_h2_summ\", w_h2)\n",
        "tf.summary.histogram(\"w_o_summ\", w_o)\n",
        "'''\n",
        "\n",
        "#Step 5 - Add dropout to input and hidden layers\n",
        "p_keep_input = tf.placeholder(\"float\", name=\"p_keep_input\")\n",
        "p_keep_hidden = tf.placeholder(\"float\", name=\"p_keep_hidden\")\n",
        "\n",
        "\n",
        "\n",
        "#Step 6 - Create Model\n",
        "#py_x = fully_connected_net(X, w_h, w_h2, w_o, p_keep_input, p_keep_hidden)\n",
        "py_x, fc1 = conv_net(X, trY[0,:].size, 0.25, is_training, reuse=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##########################################\n",
        "## COST + TRAIN_STEP\n",
        "#########################################\n",
        "#Step 7 Create cost function\n",
        "with tf.name_scope(\"cost\"):\n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=py_x,labels= Y))\n",
        "    train_op = tf.train.RMSPropOptimizer(0.0005, 0.7).minimize(cost)\n",
        "    # Add scalar summary for cost tensor\n",
        "    tf.summary.scalar(\"cost\", cost)\n",
        "\n",
        "#Step 8 Measure accuracy\n",
        "with tf.name_scope(\"accuracy\"):\n",
        "    correct_pred = tf.equal(tf.argmax(Y, 1), tf.argmax(py_x, 1)) # Count correct predictions\n",
        "    acc_op = tf.reduce_mean(tf.cast(correct_pred, \"float\")) # Cast boolean to float to average\n",
        "    # Add scalar summary for accuracy tensor\n",
        "    tf.summary.scalar(\"accuracy\", acc_op)\n",
        "   \n",
        "  \n",
        "  \n",
        "##########################################\n",
        "## PLOT INCORRECT PREDICTIONS\n",
        "#########################################\n",
        "with tf.variable_scope('Failed_test_examples'):\n",
        "  incorrect_pred = tf.not_equal(tf.argmax(Y, 1), tf.argmax(py_x, 1))\n",
        "  indices = tf.where(incorrect_pred)\n",
        "  x_arr = tf.reshape(X, shape=[-1, img_size, img_size, 1])\n",
        "  x_arr_reduced = tf.gather_nd(x_arr, indices)\n",
        "  imgy2 = tf.reshape(x_arr_reduced, [-1, img_size, img_size, 1])  \n",
        "  to_tensi = tf.summary.image('Test', imgy2 ,max_outputs=5)\n",
        "  \n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "    \n",
        "###############\n",
        "##########################################\n",
        "## SESSION / ACTUAL RUN\n",
        "#########################################\n",
        "###############\n",
        "#Step 9 Create a session\n",
        "acc_arr = []\n",
        "episodes = []\n",
        "n_episodes = 300\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    #sess = tf_debug.TensorBoardDebugWrapperSession(sess, \"localhost:6064\")\n",
        "    \n",
        "\n",
        "    # Define directory name to log on.\n",
        "    fily = str(now.year) + '_' + str(now.month) + '_' + str(now.day) + '_' + str(now.hour) + 'h_' + str(now.minute)\n",
        "    fily = './logs/' + fily\n",
        "    #test_writer = tf.train.SummaryWriter(this_test)\n",
        "    writer = tf.summary.FileWriter(fily, sess.graph) # for 0.8\n",
        "    merged = tf.summary.merge_all()\n",
        "\n",
        "    # Step 11 you need to initialize all variables\n",
        "    tf.initialize_all_variables().run()\n",
        "    #file_name = os.path.join(dirname, 'logs/events.out.tfevents.1539591730.NTNU15406')\n",
        "    saver = tf.train.Saver()\n",
        "    #saver.restore(sess, tf.train.latest_checkpoint(file_name))      ## if you want to get e.g. weights from a last session you can do it here!!!!!!!!\n",
        "\n",
        "    #Step 12 train the  model\n",
        "    for i in range(n_episodes):\n",
        "        #if(i==0):\n",
        "            #saver.restore(sess, './logs/Last_model')\n",
        "        n_batch = 60\n",
        "        batch_bool = 0\n",
        "        if(batch_bool==0):\n",
        "            for start, end in zip(range(0, len(trX), 128), range(128, len(trX)+1, 128)):\n",
        "                sess.run(train_op,                    feed_dict={X: trX[start:end].astype(np.float32), Y: trY[start:end].astype(np.float32),p_keep_input: 0.8, p_keep_hidden: 0.5, is_training: True})\n",
        "        else:\n",
        "            for b in range(int(trX[0,:].size/n_batch)):\n",
        "                batch_xs = trX[b*n_batch:b*n_batch+n_batch]\n",
        "                batch_ys = trY[b*n_batch:b*n_batch+n_batch]\n",
        "                sess.run(train_op, feed_dict={X: batch_xs, Y: batch_ys, p_keep_input: 0.8, p_keep_hidden: 0.5,is_training: True})\n",
        "\n",
        "        indi, summary, acc = sess.run([indices, merged, acc_op], feed_dict={X: teX.astype(np.float32), Y: teY.astype(np.float32),p_keep_input: 1.0, p_keep_hidden: 1.0,is_training: False, failed_object: 0,failed_object_string: \"0\"})\n",
        "\n",
        "\n",
        "        writer.add_summary(summary, i)  # Write summary\n",
        "        print(i, acc)                   # Report the accuracy\n",
        "        acc_arr = np.append(acc_arr,acc)\n",
        "        episodes = np.append(episodes, i)\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "       \n",
        "    \n",
        "    \n",
        "  \n",
        "  \n",
        " \n",
        "        \n",
        "#######################\n",
        "## PLOT ACCURACY CURVE\n",
        "######################\n",
        "\n",
        "matplotlib.get_backend()\n",
        "plt.plot(np.arange(0,n_episodes), acc_arr)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Episodes')\n",
        "plt.ylim(0,1)\n",
        "titlestring = 'Accuracy development during learning to count up to ' + str(trY[0].size) + ' object with a CNN'\n",
        "plt.title(titlestring)\n",
        "plt.savefig('Standard_NN.png')\n",
        "#plt.plot([1,2,3], [1,1,1])\n",
        "plt.show()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20001, 784)\n",
            "(20001, 8)\n",
            "(2001, 784)\n",
            "(2001, 8)\n",
            "0 0.21139431\n",
            "1 0.35182407\n",
            "2 0.4627686\n",
            "3 0.5087456\n",
            "4 0.62968516\n",
            "5 0.6956522\n",
            "6 0.6621689\n",
            "7 0.75762117\n",
            "8 0.8115942\n",
            "9 0.8135932\n",
            "10 0.81509244\n",
            "11 0.8725637\n",
            "12 0.87356323\n",
            "13 0.878061\n",
            "14 0.9115442\n",
            "15 0.7916042\n",
            "16 0.86856574\n",
            "17 0.8325837\n",
            "18 0.7856072\n",
            "19 0.936032\n",
            "20 0.8350825\n",
            "21 0.93853074\n",
            "22 0.948026\n",
            "23 0.9490255\n",
            "24 0.9545227\n",
            "25 0.92703646\n",
            "26 0.95002496\n",
            "27 0.894053\n",
            "28 0.9545227\n",
            "29 0.93253374\n",
            "30 0.9585207\n",
            "31 0.95052475\n",
            "32 0.9610195\n",
            "33 0.9585207\n",
            "34 0.96251875\n",
            "35 0.96201897\n",
            "36 0.9170415\n",
            "37 0.92253876\n",
            "38 0.9645177\n",
            "39 0.9610195\n",
            "40 0.96851575\n",
            "41 0.96251875\n",
            "42 0.90904546\n",
            "43 0.922039\n",
            "44 0.96651673\n",
            "45 0.95752126\n",
            "46 0.96951526\n",
            "47 0.96351826\n",
            "48 0.972014\n",
            "49 0.87306345\n",
            "50 0.974013\n",
            "51 0.97451276\n",
            "52 0.976012\n",
            "53 0.9715142\n",
            "54 0.9630185\n",
            "55 0.974013\n",
            "56 0.9650175\n",
            "57 0.970015\n",
            "58 0.97451276\n",
            "59 0.97351325\n",
            "60 0.83208394\n",
            "61 0.978011\n",
            "62 0.9705147\n",
            "63 0.970015\n",
            "64 0.9690155\n",
            "65 0.97251374\n",
            "66 0.96951526\n",
            "67 0.96651673\n",
            "68 0.96951526\n",
            "69 0.974013\n",
            "70 0.97551227\n",
            "71 0.9765117\n",
            "72 0.9730135\n",
            "73 0.9790105\n",
            "74 0.97251374\n",
            "75 0.9690155\n",
            "76 0.9790105\n",
            "77 0.93903047\n",
            "78 0.9770115\n",
            "79 0.9810095\n",
            "80 0.92253876\n",
            "81 0.9750125\n",
            "82 0.9470265\n",
            "83 0.98001\n",
            "84 0.97351325\n",
            "85 0.98050976\n",
            "86 0.97451276\n",
            "87 0.98001\n",
            "88 0.98150927\n",
            "89 0.9770115\n",
            "90 0.9790105\n",
            "91 0.97851074\n",
            "92 0.9810095\n",
            "93 0.9810095\n",
            "94 0.9790105\n",
            "95 0.9010495\n",
            "96 0.97251374\n",
            "97 0.9690155\n",
            "98 0.9835082\n",
            "99 0.9850075\n",
            "100 0.98050976\n",
            "101 0.98150927\n",
            "102 0.982009\n",
            "103 0.9830085\n",
            "104 0.8935532\n",
            "105 0.9715142\n",
            "106 0.98150927\n",
            "107 0.82008994\n",
            "108 0.9790105\n",
            "109 0.83408296\n",
            "110 0.97551227\n",
            "111 0.9790105\n",
            "112 0.976012\n",
            "113 0.97951025\n",
            "114 0.9770115\n",
            "115 0.9775112\n",
            "116 0.984008\n",
            "117 0.982009\n",
            "118 0.982009\n",
            "119 0.97951025\n",
            "120 0.97851074\n",
            "121 0.9610195\n",
            "122 0.9835082\n",
            "123 0.984008\n",
            "124 0.9810095\n",
            "125 0.98050976\n",
            "126 0.96751624\n",
            "127 0.97951025\n",
            "128 0.9750125\n",
            "129 0.97451276\n",
            "130 0.9850075\n",
            "131 0.87906045\n",
            "132 0.9790105\n",
            "133 0.964018\n",
            "134 0.9825087\n",
            "135 0.95602196\n",
            "136 0.98150927\n",
            "137 0.98001\n",
            "138 0.96051973\n",
            "139 0.97951025\n",
            "140 0.91054475\n",
            "141 0.9525237\n",
            "142 0.96751624\n",
            "143 0.984008\n",
            "144 0.98050976\n",
            "145 0.9810095\n",
            "146 0.94052976\n",
            "147 0.9790105\n",
            "148 0.9825087\n",
            "149 0.9790105\n",
            "150 0.9730135\n",
            "151 0.9830085\n",
            "152 0.96851575\n",
            "153 0.98050976\n",
            "154 0.96201897\n",
            "155 0.984008\n",
            "156 0.98550725\n",
            "157 0.97851074\n",
            "158 0.9825087\n",
            "159 0.9825087\n",
            "160 0.9810095\n",
            "161 0.986007\n",
            "162 0.9825087\n",
            "163 0.96851575\n",
            "164 0.984008\n",
            "165 0.9630185\n",
            "166 0.9875063\n",
            "167 0.9825087\n",
            "168 0.982009\n",
            "169 0.9835082\n",
            "170 0.95052475\n",
            "171 0.982009\n",
            "172 0.9825087\n",
            "173 0.98450774\n",
            "174 0.9775112\n",
            "175 0.9830085\n",
            "176 0.92853576\n",
            "177 0.982009\n",
            "178 0.98450774\n",
            "179 0.870065\n",
            "180 0.8995502\n",
            "181 0.97351325\n",
            "182 0.9765117\n",
            "183 0.93153423\n",
            "184 0.9765117\n",
            "185 0.9825087\n",
            "186 0.9470265\n",
            "187 0.98450774\n",
            "188 0.94652677\n",
            "189 0.95052475\n",
            "190 0.98150927\n",
            "191 0.98150927\n",
            "192 0.984008\n",
            "193 0.984008\n",
            "194 0.9835082\n",
            "195 0.9305347\n",
            "196 0.93953025\n",
            "197 0.98001\n",
            "198 0.9190405\n",
            "199 0.9825087\n",
            "200 0.9810095\n",
            "201 0.978011\n",
            "202 0.9825087\n",
            "203 0.9305347\n",
            "204 0.97351325\n",
            "205 0.9775112\n",
            "206 0.93353325\n",
            "207 0.96651673\n",
            "208 0.98150927\n",
            "209 0.978011\n",
            "210 0.984008\n",
            "211 0.9730135\n",
            "212 0.982009\n",
            "213 0.9810095\n",
            "214 0.984008\n",
            "215 0.982009\n",
            "216 0.982009\n",
            "217 0.98150927\n",
            "218 0.98150927\n",
            "219 0.9835082\n",
            "220 0.96751624\n",
            "221 0.96151924\n",
            "222 0.98550725\n",
            "223 0.95552224\n",
            "224 0.93453276\n",
            "225 0.9825087\n",
            "226 0.984008\n",
            "227 0.9775112\n",
            "228 0.978011\n",
            "229 0.98050976\n",
            "230 0.98050976\n",
            "231 0.978011\n",
            "232 0.9835082\n",
            "233 0.9595202\n",
            "234 0.9885057\n",
            "235 0.9850075\n",
            "236 0.942029\n",
            "237 0.9850075\n",
            "238 0.87506247\n",
            "239 0.98550725\n",
            "240 0.9835082\n",
            "241 0.984008\n",
            "242 0.98001\n",
            "243 0.988006\n",
            "244 0.9835082\n",
            "245 0.9770115\n",
            "246 0.9765117\n",
            "247 0.9830085\n",
            "248 0.98001\n",
            "249 0.982009\n",
            "250 0.97951025\n",
            "251 0.9835082\n",
            "252 0.970015\n",
            "253 0.98001\n",
            "254 0.9830085\n",
            "255 0.9790105\n",
            "256 0.98650676\n",
            "257 0.9875063\n",
            "258 0.98550725\n",
            "259 0.9870065\n",
            "260 0.916042\n",
            "261 0.96751624\n",
            "262 0.98150927\n",
            "263 0.97551227\n",
            "264 0.9835082\n",
            "265 0.9870065\n",
            "266 0.9850075\n",
            "267 0.9890055\n",
            "268 0.98550725\n",
            "269 0.9850075\n",
            "270 0.9830085\n",
            "271 0.98650676\n",
            "272 0.9765117\n",
            "273 0.9830085\n",
            "274 0.97451276\n",
            "275 0.9830085\n",
            "276 0.9590205\n",
            "277 0.97551227\n",
            "278 0.982009\n",
            "279 0.984008\n",
            "280 0.9195402\n",
            "281 0.9885057\n",
            "282 0.9825087\n",
            "283 0.98550725\n",
            "284 0.95652175\n",
            "285 0.9655172\n",
            "286 0.96751624\n",
            "287 0.9850075\n",
            "288 0.9790105\n",
            "289 0.9885057\n",
            "290 0.984008\n",
            "291 0.9195402\n",
            "292 0.9850075\n",
            "293 0.9830085\n",
            "294 0.982009\n",
            "295 0.98450774\n",
            "296 0.9885057\n",
            "297 0.9870065\n",
            "298 0.98550725\n",
            "299 0.9810095\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAEWCAYAAADrfqfPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRGZ7Vz4dHXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#######################################\n",
        "## TRASH, meanwhile\n",
        "########################################\n",
        "\n",
        "\n",
        "# Initialize the embedding variable with the shape of our desired tensor\n",
        "tensor_shape = (trX.shape[0] , fc1.get_shape()[1].value) # [test_set , h1] = [10000 , 200]\n",
        "embedding_var = tf.Variable(tf.zeros(tensor_shape), \n",
        "                            name='fc1_embedding')\n",
        "# assign the tensor that we want to visualize to the embedding variable\n",
        "embedding_assign = embedding_var.assign(fc1) \n",
        "\n",
        "from tensorflow.contrib.tensorboard.plugins import projector\n",
        "\n",
        "# Create a config object to write the configuration parameters\n",
        "config = projector.ProjectorConfig()\n",
        "\n",
        "# Add embedding variable\n",
        "embedding = config.embeddings.add()\n",
        "embedding.tensor_name = embedding_var.name\n",
        "\n",
        "# Link this tensor to its metadata file (e.g. labels) -> we will create this file later\n",
        "embedding.metadata_path = 'metadata.tsv'\n",
        "\n",
        "# Specify where you find the sprite. -> we will create this image later\n",
        "embedding.sprite.image_path = 'sprite_images.png'\n",
        "embedding.sprite.single_image_dim.extend([img_w, img_h])\n",
        "\n",
        "# Write a projector_config.pbtxt in the logs_path.\n",
        "# TensorBoard will read this file during startup.\n",
        "projector.visualize_embeddings(train_writer, config)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Run session to evaluate the tensor\n",
        "x_test_fc1 = sess.run(embedding_assign, feed_dict={x: x_test})\n",
        "\n",
        "# Save the tensor in model.ckpt file\n",
        "saver = tf.train.Saver()\n",
        "saver.save(sess, os.path.join(logs_path, \"model.ckpt\"), global_step)\n",
        "\n",
        "\n",
        "\n",
        " '''\n",
        "        #################################################################################\n",
        "        # Load the test set\n",
        "        x_test = teX\n",
        "        y_test = teY\n",
        "\n",
        "        fc1 = sess.run(fc1, feed_dict={X: teX.astype(np.float32), Y: teY.astype(np.float32),p_keep_input: 1.0, p_keep_hidden: 1.0,is_training: False, failed_object: 0,failed_object_string: \"0\"})\n",
        "\n",
        "        # Initialize the embedding variable with the shape of our desired tensor\n",
        "        tensor_shape = (x_test.shape[0] , fc1.shape[1]) # [test_set , h1] = [10000 , 200]\n",
        "        embedding_var = tf.Variable(tf.zeros(tensor_shape), \n",
        "                                    name='fc1_embedding')\n",
        "        # assign the tensor that we want to visualize to the embedding variable\n",
        "        embedding_assign = embedding_var.assign(fc1) \n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "        # Create a config object to write the configuration parameters\n",
        "        config = projector.ProjectorConfig()\n",
        "\n",
        "        # Add embedding variable\n",
        "        embedding = config.embeddings.add()\n",
        "        embedding.tensor_name = embedding_var.name\n",
        "\n",
        "        # Link this tensor to its metadata file (e.g. labels) -> we will create this file later\n",
        "        embedding.metadata_path = 'metadata.tsv'\n",
        "\n",
        "        # Specify where you find the sprite. -> we will create this image later\n",
        "        embedding.sprite.image_path = 'sprite_images.png'\n",
        "        embedding.sprite.single_image_dim.extend(trX[0].shape)   #[img_w, img_h]\n",
        "\n",
        "        # Write a projector_config.pbtxt in the logs_path.\n",
        "        # TensorBoard will read this file during startup.\n",
        "        projector.visualize_embeddings(writer, config)\n",
        "\n",
        "\n",
        "\n",
        "          \n",
        "        \n",
        "         # Run session to evaluate the tensor\n",
        "        x_test_fc1 = sess.run(embedding_assign, feed_dict={x: x_test})\n",
        "\n",
        "        # Save the tensor in model.ckpt file\n",
        "        saver = tf.train.Saver()\n",
        "        saver.save(sess, os.path.join(logs_path, \"model.ckpt\"), global_step)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        def write_sprite_image(filename, images):\n",
        "          \"\"\"\n",
        "              Create a sprite image consisting of sample images\n",
        "              :param filename: name of the file to save on disk\n",
        "              :param shape: tensor of flattened images\n",
        "          \"\"\"\n",
        "\n",
        "          # Invert grayscale image\n",
        "          images = 1 - images\n",
        "\n",
        "          # Calculate number of plot\n",
        "          n_plots = int(np.ceil(np.sqrt(images.shape[0])))\n",
        "\n",
        "          # Make the background of sprite image\n",
        "          sprite_image = np.ones((img_h * n_plots, img_w * n_plots))\n",
        "\n",
        "          for i in range(n_plots):\n",
        "              for j in range(n_plots):\n",
        "                  img_idx = i * n_plots + j\n",
        "                  if img_idx < images.shape[0]:\n",
        "                      img = images[img_idx]\n",
        "                      sprite_image[i * img_h:(i + 1) * img_h,\n",
        "                      j * img_w:(j + 1) * img_w] = img\n",
        "\n",
        "          plt.imsave(filename, sprite_image, cmap='gray')\n",
        "          print('Sprite image saved in {}'.format(filename))\n",
        "\n",
        "        def write_metadata(filename, labels):\n",
        "            \"\"\"\n",
        "                    Create a metadata file image consisting of sample indices and labels\n",
        "                    :param filename: name of the file to save on disk\n",
        "                    :param shape: tensor of labels\n",
        "            \"\"\"\n",
        "            with open(filename, 'w') as f:\n",
        "                f.write(\"Index\\tLabel\\n\")\n",
        "                for index, label in enumerate(labels):\n",
        "                    f.write(\"{}\\t{}\\n\".format(index, label))\n",
        "\n",
        "            print('Metadata file saved in {}'.format(filename))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Reshape images from vector to matrix\n",
        "        x_test_images = np.reshape(np.array(x_test), (-1, img_w, img_h))\n",
        "        # Reshape labels from one-hot-encode to index\n",
        "        x_test_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "        write_sprite_image(os.path.join(logs_path, 'sprite_images.png'), x_test_images)\n",
        "        write_metadata(os.path.join(logs_path, 'metadata.tsv'), x_test_labels)\n",
        "    \n",
        "    \n",
        "        '''    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}